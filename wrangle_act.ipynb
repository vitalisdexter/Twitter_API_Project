{"cells":[{"cell_type":"markdown","metadata":{"extensions":{"jupyter_dashboards":{"version":1,"views":{"grid_default":{"col":0,"height":4,"hidden":false,"row":0,"width":4},"report_default":{"hidden":false}}}},"id":"spqQykOSmrHt"},"source":["# Project: Wrangling and Analyze Data"]},{"cell_type":"markdown","metadata":{"id":"BQuAIWogmrH0"},"source":["## Data Gathering\n","In the cell below, gather **all** three pieces of data for this project and load them in the notebook. **Note:** the methods required to gather each data are different.\n","1. Directly download the WeRateDogs Twitter archive data (twitter_archive_enhanced.csv)"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":false,"id":"nCzAXQBxmrH1"},"outputs":[],"source":["# Install Libraries for the first time\n","\n","# !pip install tweepy\n","# !pip install configparser"]},{"cell_type":"code","execution_count":null,"metadata":{"extensions":{"jupyter_dashboards":{"version":1,"views":{"grid_default":{"hidden":true},"report_default":{"hidden":true}}}},"id":"W7clB2YqmrH1"},"outputs":[],"source":["# Import necesaries Libraries\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import requests\n","import os\n","import time\n","import tweepy\n","import tweepy\n","import configparser\n","import json\n","import time\n","import re\n","import seaborn as sns\n","%matplotlib inline\n","config = configparser.ConfigParser()\n","config.read('config.ini')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-9uxYvZomrH1"},"outputs":[],"source":["#Importing the tweets archive and converting it into a dataframe\n","\n","df_twitter_archive = pd.read_csv('twitter-archive-enhanced.csv')"]},{"cell_type":"markdown","metadata":{"id":"lKl2BVU9mrH1"},"source":["2. Use the Requests library to download the tweet image prediction (image_predictions.tsv)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"18Ol2WPwmrH2"},"outputs":[],"source":["# Downloading image prediction file using Requests library\n","\n","img_url = 'https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\n","img_request = requests.get(img_url, allow_redirects=True)\n","\n","open('image_predictions.tsv', 'wb').write(img_request.content)"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":false,"id":"ORlsyJjTmrH2"},"outputs":[],"source":["# Using Pandas, we convert the tsv file into a Dataframe\n","\n","df_image_predictions = pd.read_csv('image_predictions.tsv', sep='\\t')\n","df_image_predictions.head()"]},{"cell_type":"markdown","metadata":{"id":"GyYciL1UmrH2"},"source":["3. Use the Tweepy library to query additional data via the Twitter API (tweet_json.txt)"]},{"cell_type":"markdown","metadata":{"id":"24zVtlhxmrH2"},"source":["**I will comment out the Tweepy codes. To run this section that has to deal with the Twitter API, first open the config.ini file and enter your own Twitter API details there.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lO5fDjSZmrH2"},"outputs":[],"source":["# # To protect my Twitter API Keys, I use Configparser to declare the API keys and hide them.\n","\n","# consumer_key = config['twitter']['consumer_key']\n","# consumer_secret = config['twitter']['consumer_secret']\n","# access_token = config['twitter']['access_token']\n","# access_secret = config['twitter']['access_secret']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dBZuOWoGmrH2"},"outputs":[],"source":["# # Assign the API keys from COnfigparser to Tweepy variables\n","\n","# auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n","# auth.set_access_token(access_token, access_secret)\n","# api = tweepy.API(auth)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D96w8vtVmrH3"},"outputs":[],"source":["# # Pull a tweet from Twitter to test if the API connect is working.\n","\n","# api.get_status(df_twitter_archive.tweet_id[1000]).text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zzaCx3bhmrH3"},"outputs":[],"source":["# # Declare an empty array to save all json data that will be collected from Twitter\n","\n","# tweet_list = []\n","\n","# # Declare an array to save the IDs that could not be fetched\n","\n","# tweet_failure = []\n","\n","# # Loop through the tweet id column and fetch the data from Twitter\n","\n","# for tweet_id in df_twitter_archive.tweet_id:\n","#     try:\n","#         tweet_list.append(api.get_status(tweet_id, tweet_mode='extended'))\n","#     except Exception as e:\n","#         tweet_failure.append(tweet_id)"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"NSF-toZjmrH3"},"outputs":[],"source":["# # Print the total number of successful IDs and  number of failed IDs using len function\n","\n","# print(\"The list of tweets\" ,len(tweet_list))\n","# print(\"The list of tweets no found\" , len(tweet_failure))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZRNfm1jomrH3"},"outputs":[],"source":["# tweet_dicts = []\n","# for i in tweet_list:\n","#     tweet_dicts.append(i._json)\n","\n","# #We write this list into a txt file\n","\n","# with open('tweet_json.txt', 'w') as file:\n","#         file.write(json.dumps(tweet_dicts, indent=4))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MvKrtZW9mrH3"},"outputs":[],"source":["# # View the json file to identify what to extract\n","\n","# tweet_dicts"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X6w6cAcMmrH3"},"outputs":[],"source":["# Extract relevant data from the JSON file and store it in a list\n","\n","tweets_list = []\n","with open('tweet_json.txt', encoding='utf-8') as json_file:\n","    all_meta_data = json.load(json_file)\n","    for tweet_dictionary in all_meta_data:\n","        tweet_id = tweet_dictionary['id']\n","        tweet_text = tweet_dictionary['full_text']\n","        only_url = tweet_text[tweet_text.find('https'):]\n","        favorite_count = tweet_dictionary['favorite_count']\n","        retweet_count = tweet_dictionary['retweet_count']\n","        whole_source = tweet_dictionary['source']\n","        only_device = whole_source[whole_source.find('rel=\"nofollow\">') + 15:-4]\n","        source = only_device\n","        retweeted_status = tweet_dictionary['retweeted_status'] = tweet_dictionary.get('retweeted_status', 'Original tweet')\n","        if retweeted_status == 'Original tweet':\n","            url = only_url\n","        else:\n","            retweeted_status = 'This is a retweet'\n","            url = 'This is a retweet'\n","\n","        tweets_list.append({'tweet_id': str(tweet_id),\n","                             'favorite_count': int(favorite_count),\n","                             'retweet_count': int(retweet_count),\n","                             'url': url,\n","                             'source': source,\n","                             'retweeted_status': retweeted_status,\n","                            })\n","        df_counts = pd.DataFrame(tweets_list, columns = ['tweet_id','favorite_count','retweet_count',\n","                                                           'source', 'retweeted_status', 'url'])\n","df_counts.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":false,"id":"Ey9MHr7ymrH3"},"outputs":[],"source":["df_counts.sample(10)"]},{"cell_type":"markdown","metadata":{"extensions":{"jupyter_dashboards":{"version":1,"views":{"grid_default":{"col":4,"height":4,"hidden":false,"row":28,"width":4},"report_default":{"hidden":false}}}},"id":"tB6fKU5qmrH3"},"source":["## Assessing Data\n","In this section, detect and document at least **eight (8) quality issues and two (2) tidiness issue**. You must use **both** visual assessment\n","programmatic assessement to assess the data.\n","\n","**Note:** pay attention to the following key points when you access the data.\n","\n","* You only want original ratings (no retweets) that have images. Though there are 5000+ tweets in the dataset, not all are dog ratings and some are retweets.\n","* Assessing and cleaning the entire dataset completely would require a lot of time, and is not necessary to practice and demonstrate your skills in data wrangling. Therefore, the requirements of this project are only to assess and clean at least 8 quality issues and at least 2 tidiness issues in this dataset.\n","* The fact that the rating numerators are greater than the denominators does not need to be cleaned. This [unique rating system](http://knowyourmeme.com/memes/theyre-good-dogs-brent) is a big part of the popularity of WeRateDogs.\n","* You do not need to gather the tweets beyond August 1st, 2017. You can, but note that you won't be able to gather the image predictions for these tweets since you don't have access to the algorithm used.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"NtlUwoCrmrH4"},"source":["### Archive Dataframe Analysis\n","In this section, the different dataframes will be anayzed for **Completeness**, **Validity**, **Accuracy** and **Consistency**"]},{"cell_type":"markdown","metadata":{"id":"Ka_VocbkmrH4"},"source":["#### Visual Assesment\n","Every dataframe that will be analyzed is first assesed visually for QUality and Tidiness issues. I will be using sample 50 to select 50 random columns to access visually."]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"m68OU1nemrH4"},"outputs":[],"source":["df_twitter_archive.sample(50)"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":false,"id":"GPZsWHJymrH4"},"outputs":[],"source":["df_image_predictions.sample(50)"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"bxI1UV02mrH4"},"outputs":[],"source":["df_counts.sample(50)"]},{"cell_type":"markdown","metadata":{"id":"cbrKVLYtmrH4"},"source":["Display image url tutorial from https://stackoverflow.com/questions/11854847/how-can-i-display-an-image-from-a-file-in-jupyter-notebook"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":false,"id":"XO3wkW_JmrH4"},"outputs":[],"source":["# testing the image url\n","\n","from IPython.display import Image\n","Image(url = df_image_predictions.jpg_url[380])"]},{"cell_type":"markdown","metadata":{"id":"ZAAo4s_ymrH5"},"source":["#### Programatic Assessment\n","Here I will be using Panda Functions and methods to assess the data for quaity and tidiness issues"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"-4hLEM93mrH5"},"outputs":[],"source":["df_twitter_archive.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vn5MEW5TmrH5"},"outputs":[],"source":["df_image_predictions.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"6JRJBCmBmrH5"},"outputs":[],"source":["df_counts.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TSIs4UqBmrH5"},"outputs":[],"source":["df_twitter_archive.describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"99Mf2HeKmrH6"},"outputs":[],"source":["df_counts.describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R89Jo9vxmrH6"},"outputs":[],"source":["df_image_predictions.describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HWkJXzmqmrH6"},"outputs":[],"source":["df_twitter_archive.name.value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XX87GiUgmrH6"},"outputs":[],"source":["df_image_predictions.p1.value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U-PedzzFmrH6"},"outputs":[],"source":["df_twitter_archive[df_twitter_archive.tweet_id.duplicated()]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NJH9zSxdmrH6"},"outputs":[],"source":["df_counts[df_counts.tweet_id.duplicated()]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"txKc7cTGmrH6"},"outputs":[],"source":["df_image_predictions[df_image_predictions.tweet_id.duplicated()]"]},{"cell_type":"markdown","metadata":{"id":"tsQ65Q_dmrH6"},"source":["### Quality issues\n","1. Add decimals to Rating Numerator\n","\n","2. Fix Dog Ratings\n","\n","3. Change Timestamp to Correct Date time format\n","\n","4. Remove every Retweet\n","\n","5. Fix Errors with Dog Names\n","\n","6. Some records have multiple dog stages\n","\n","7. Drop Unwanted columns\n","\n","8. Fix Erroneous Datatypes in most columns"]},{"cell_type":"markdown","metadata":{"extensions":{"jupyter_dashboards":{"version":1,"views":{"grid_default":{"col":0,"height":7,"hidden":false,"row":40,"width":12},"report_default":{"hidden":false}}}},"id":"X98RmeWGmrH7"},"source":["### Tidiness issues\n","1. Merge all 3 Dataframes to be one master Dataframe\n","\n","2. Creating a dog breed column using data from image prediction\n","\n","3. Remove tweets with no image"]},{"cell_type":"markdown","metadata":{"extensions":{"jupyter_dashboards":{"version":1,"views":{"grid_default":{"col":4,"height":4,"hidden":false,"row":32,"width":4},"report_default":{"hidden":false}}}},"id":"uPvsz5TkmrH7"},"source":["## Cleaning Data\n","In this section, clean **all** of the issues you documented while assessing.\n","\n","**Note:** Make a copy of the original data before cleaning. Cleaning includes merging individual pieces of data according to the rules of [tidy data](https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html). The result should be a high-quality and tidy master pandas DataFrame (or DataFrames, if appropriate)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ldm-wG73mrH7"},"outputs":[],"source":["# Make copies of original pieces of data\n","twitter_archive_clean = df_twitter_archive.copy()\n","image_predictions_clean = df_image_predictions.copy()\n","tweets_meta_count = df_counts.copy()"]},{"cell_type":"markdown","metadata":{"id":"f-ET6ylZmrH7"},"source":["### Quality Issue 1: Add decimals to Rating Numerator"]},{"cell_type":"markdown","metadata":{"id":"YT0LP5xRmrH7"},"source":["#### Define:\n","- Convert rating numerator and denominator to float from int"]},{"cell_type":"markdown","metadata":{"id":"Ilko3a4EmrH7"},"source":["#### Code"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bLEuFekamrH8"},"outputs":[],"source":["twitter_archive_clean.rating_numerator = twitter_archive_clean.rating_numerator.astype(float)\n","twitter_archive_clean.rating_denominator = twitter_archive_clean.rating_denominator.astype(float)"]},{"cell_type":"markdown","metadata":{"id":"gs8v2WdBmrH8"},"source":["#### Test"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"3ntCc1kPmrH8"},"outputs":[],"source":["twitter_archive_clean.info()"]},{"cell_type":"markdown","metadata":{"id":"HQjc8qQTmrH8"},"source":["### Quality Issue 2: Fix Dog rating system"]},{"cell_type":"markdown","metadata":{"id":"12Puo97dmrH8"},"source":["#### Define\n","- Check twitter_archive_clean for columns where ratings are not extrated properly"]},{"cell_type":"markdown","metadata":{"id":"rc4CfObVmrH9"},"source":["#### Code"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"pN5PToE3mrH9"},"outputs":[],"source":["with pd.option_context('max_colwidth', 200):\n","    display(twitter_archive_clean[twitter_archive_clean.text.str.contains(r\"(\\d+\\.\\d*\\/\\d+)\")]\n","            [['tweet_id', 'text', 'rating_numerator', 'rating_denominator']])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H4oQK1-XmrH9"},"outputs":[],"source":["# Print the indices of the ratings above (have decimal)\n","twitter_archive_clean.loc[(twitter_archive_clean.tweet_id == 883482846933004288), 'rating_numerator'] = 13.5\n","twitter_archive_clean.loc[(twitter_archive_clean.tweet_id == 832215909146226688), 'rating_numerator'] = 9.75\n","twitter_archive_clean.loc[(twitter_archive_clean.tweet_id == 786709082849828864), 'rating_numerator'] = 9.75\n","twitter_archive_clean.loc[(twitter_archive_clean.tweet_id == 778027034220126208), 'rating_numerator'] = 11.27\n","twitter_archive_clean.loc[(twitter_archive_clean.tweet_id == 681340665377193984), 'rating_numerator'] = 9.5\n","twitter_archive_clean.loc[(twitter_archive_clean.tweet_id == 680494726643068929), 'rating_numerator'] = 11.26"]},{"cell_type":"markdown","metadata":{"id":"odCVzdNGmrH9"},"source":["#### Test"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"pT5IBitqmrH9"},"outputs":[],"source":["with pd.option_context('max_colwidth', 200):\n","    display(twitter_archive_clean[twitter_archive_clean.text.str.contains(r\"(\\d+\\.\\d*\\/\\d+)\")]\n","            [['tweet_id', 'text', 'rating_numerator', 'rating_denominator']])"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"aG81yIQxmrH9"},"outputs":[],"source":["image_predictions_clean[(image_predictions_clean.tweet_id == 786709082849828864)].index"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"muQLbuH8mrH9"},"outputs":[],"source":["twitter_archive_clean# Logan's rating was 75/10 now it is fixed 9.75/10\n","twitter_archive_clean.loc[(twitter_archive_clean.tweet_id == 786709082849828864),'rating_numerator':'rating_denominator']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6PpOPMSCmrH-"},"outputs":[],"source":["# Logan's cute image\n","from IPython.display import Image\n","Image(url = image_predictions_clean.jpg_url[1515])"]},{"cell_type":"markdown","metadata":{"id":"Fa39nscLmrH-"},"source":["### Quality Issue #3: Change Timestamp to Correct Datetime Object"]},{"cell_type":"markdown","metadata":{"id":"UgULzbD_mrH-"},"source":["#### Define\n","- Removing time zone from the Timestamp column\n","- Change it to a datetime object"]},{"cell_type":"markdown","metadata":{"id":"Qj9Fz2jZmrH-"},"source":["#### Code"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1nw2E8nnmrH-"},"outputs":[],"source":["twitter_archive_clean['timestamp'] = twitter_archive_clean['timestamp'].str.slice(start=0, stop=-6)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eGUvBjdBmrH-"},"outputs":[],"source":["twitter_archive_clean['timestamp'] = pd.to_datetime(twitter_archive_clean['timestamp'], format = \"%Y-%m-%d %H:%M:%S\")"]},{"cell_type":"markdown","metadata":{"id":"QK52pxNNmrH-"},"source":["#### Test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NdlHScm8mrH-"},"outputs":[],"source":["twitter_archive_clean.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"u4HxM0B-mrH-"},"outputs":[],"source":["twitter_archive_clean.sample(5)"]},{"cell_type":"markdown","metadata":{"id":"u-i7qV2MmrH_"},"source":["### Quality Issue 4: Remove every Retweet"]},{"cell_type":"markdown","metadata":{"id":"zSBDLd3gmrH_"},"source":["#### Define\n","- Delete every retweet by filtering for NaN in Retweet_status_id column"]},{"cell_type":"markdown","metadata":{"id":"zqaTVp-2mrH_"},"source":["#### Code"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WIyGUrwEmrH_"},"outputs":[],"source":["twitter_archive_clean = twitter_archive_clean[pd.isnull(twitter_archive_clean.retweeted_status_id)]"]},{"cell_type":"markdown","metadata":{"id":"QC_DsX-xmrH_"},"source":["#### Test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FCFcBpK6mrH_"},"outputs":[],"source":["twitter_archive_clean.info()"]},{"cell_type":"markdown","metadata":{"id":"cSBgZaApmrH_"},"source":["### Quality Issue 5: Fix Errors in Dog Name Column"]},{"cell_type":"markdown","metadata":{"id":"hEchpckxmrH_"},"source":["#### Define\n","- Use Regex to search for names and repace with None"]},{"cell_type":"markdown","metadata":{"id":"P7rSfOYFmrIA"},"source":["#### Code"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RknDDCPAmrIA"},"outputs":[],"source":["twitter_archive_clean.name = twitter_archive_clean.name.str.replace('^[a-z]+', 'None')"]},{"cell_type":"markdown","metadata":{"id":"kGeMBdt-mrIA"},"source":["#### Test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Low-6fyQmrIA"},"outputs":[],"source":["twitter_archive_clean.name.value_counts()"]},{"cell_type":"markdown","metadata":{"id":"75y3HcIBmrIA"},"source":["### Quality Issues 6: Some records have multiple dog stages"]},{"cell_type":"markdown","metadata":{"id":"t7mPH_H-mrIA"},"source":["#### Define\n","- Will concatenate the records in the columns that represent the dog stages to one column\n","- Create a custom function to count and compare values to return the dog stage"]},{"cell_type":"markdown","metadata":{"id":"yPgfw-6QmrIA"},"source":["#### Code"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xGFh8e8SmrIA"},"outputs":[],"source":["twitter_archive_clean['all_stage'] = twitter_archive_clean.doggo + twitter_archive_clean.floofer + twitter_archive_clean.pupper + twitter_archive_clean.puppo\n","twitter_archive_clean['all_stage'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qiVhM_IMmrIA"},"outputs":[],"source":["# Function to check the new all stage column for dog stages\n","\n","def stages_check(archive):\n","    if archive['all_stage'].count('None') == 2:\n","        return 'Multiple' #this means it has more than one dog stage\n","    else:\n","        if archive['all_stage'].count('doggo') == 1:\n","            return 'Doggo'\n","        elif archive['all_stage'].count('floofer') == 1:\n","            return 'Floofer'\n","        elif archive['all_stage'].count('pupper') == 1:\n","            return 'Pupper'\n","        elif archive['all_stage'].count('puppo') == 1:\n","            return 'Puppo'\n","        else:\n","            return 'None'\n","\n","twitter_archive_clean['dog_stages'] = twitter_archive_clean.apply(stages_check, axis=1)"]},{"cell_type":"markdown","metadata":{"id":"dOHfZR3rmrIB"},"source":["### Test"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"GHEJFJJxmrIB"},"outputs":[],"source":["twitter_archive_clean.dog_stages.value_counts()"]},{"cell_type":"markdown","metadata":{"id":"NIo_VD4WmrIB"},"source":["### Quality Issue #7: Drop Unwanted columns"]},{"cell_type":"markdown","metadata":{"id":"aaEewMzGmrIB"},"source":["#### Define\n","- Use drop function to drop columns we will not be using for this analysis from the different tables"]},{"cell_type":"markdown","metadata":{"id":"pnHBp6MgmrIB"},"source":["#### Code"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"PbIiddm_mrIB"},"outputs":[],"source":["twitter_archive_clean.columns"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":false,"id":"zfw1yUd1mrIB"},"outputs":[],"source":["image_predictions_clean.columns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CsdHdHvDmrIB"},"outputs":[],"source":["tweets_meta_count.columns"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"z2MPmP6amrIC"},"outputs":[],"source":["twitter_archive_clean.drop(['in_reply_to_status_id', 'in_reply_to_user_id','source',\n","                            'retweeted_status_id', 'retweeted_status_user_id','retweeted_status_timestamp',\n","                            'expanded_urls','doggo', 'floofer', 'pupper', 'puppo','all_stage'], axis = 1, inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l-sQBhUGmrIC"},"outputs":[],"source":["image_predictions_clean.drop(['img_num'], axis = 1, inplace=True)"]},{"cell_type":"markdown","metadata":{"id":"4pMnv8ummrIC"},"source":["### Test"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"vcraE2JOmrIC"},"outputs":[],"source":["twitter_archive_clean.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kQzlr9SpmrIC"},"outputs":[],"source":["image_predictions_clean.info()"]},{"cell_type":"markdown","metadata":{"id":"XmXFpWHjmrIC"},"source":["### Tidiness 1. Merge all 3 Dataframes to be one master Dataframe"]},{"cell_type":"markdown","metadata":{"id":"saVdos7TmrID"},"source":["#### Define\n","- Use Reduce to merge all dataframes on tweet_id"]},{"cell_type":"markdown","metadata":{"id":"HK_C1P0imrID"},"source":["#### Code"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p9nJc6WAmrID"},"outputs":[],"source":["# Merge can not compare int to object, that is why i have to convert tweets_data_clean tweet_id to int from object\n","\n","tweets_meta_count.tweet_id = pd.to_numeric(tweets_meta_count.tweet_id)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cejMQXqDmrID"},"outputs":[],"source":["# https://stackoverflow.com/questions/44327999/python-pandas-merge-multiple-dataframes/44338256\n","\n","from functools import reduce\n","merged_df = [twitter_archive_clean, image_predictions_clean, tweets_meta_count]\n","twitter_dogs = reduce(lambda left, right:  pd.merge(left, right, on = 'tweet_id'), merged_df)"]},{"cell_type":"markdown","metadata":{"id":"W31sQ1hFmrID"},"source":["#### Test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ERPCdR6cmrID"},"outputs":[],"source":["twitter_dogs.info()"]},{"cell_type":"markdown","metadata":{"id":"wVzp8dkvmrIE"},"source":["### Tidiness 2: Creating a dog breed column using data from image prediction"]},{"cell_type":"markdown","metadata":{"id":"NkPN6y8_mrIE"},"source":["#### Define\n","- Use at method to get the predicted dog breed from the data collected from image prediction"]},{"cell_type":"markdown","metadata":{"id":"szk2HMSSmrIE"},"source":["#### Code"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gv79-08FmrIE"},"outputs":[],"source":["twitter_dogs.dog_breed = 'None'\n","\n","for i, row in twitter_dogs.iterrows():\n","    if row.p1_dog:\n","        twitter_dogs.at[i, 'dog_breed']= row.p1\n","    elif row.p2_dog and row.rating_numerator >= 10:\n","        twitter_dogs.at[i, 'dog_breed']= row.p2\n","    elif row.p3_dog and row.rating_numerator >= 10:\n","        twitter_dogs.at[i, 'dog_breed']= row.p3\n","    else:\n","        twitter_dogs.at[i, 'dog_breed']='None'"]},{"cell_type":"markdown","metadata":{"id":"T0ook1WwmrIF"},"source":["#### Test"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"j7znGoC6mrIF"},"outputs":[],"source":["twitter_dogs['dog_breed'].value_counts()"]},{"cell_type":"markdown","metadata":{"id":"JTFSlkC2mrIF"},"source":["#### Define\n","- we no longer need the image prediction data se we drop them"]},{"cell_type":"markdown","metadata":{"id":"nQczXHu_mrIF"},"source":["#### Code"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CZL3RyJWmrIF"},"outputs":[],"source":["twitter_dogs.columns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xp1ViM3HmrIF"},"outputs":[],"source":["twitter_dogs.drop(['p1', 'p1_conf','p1_dog', 'p2', 'p2_conf', 'p2_dog', 'p3','retweeted_status', 'p3_conf', 'p3_dog'],\n","            axis= 1, inplace=True)"]},{"cell_type":"markdown","metadata":{"id":"JJLQAH1KmrII"},"source":["#### Test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q-kiqHQOmrII"},"outputs":[],"source":["twitter_dogs.info()"]},{"cell_type":"markdown","metadata":{"id":"1h_kfjxgmrII"},"source":["### Quality Issue #8: Fix Erroneous Datatypes in most columns"]},{"cell_type":"markdown","metadata":{"id":"4cefENEgmrII"},"source":["#### Define\n","- Convert tweet id to string\n","- Convert source, dog type, dog breed to category"]},{"cell_type":"markdown","metadata":{"id":"BdEZfg-AmrIJ"},"source":["#### Code"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SzpRh8stmrIJ"},"outputs":[],"source":["twitter_dogs.tweet_id = twitter_dogs.tweet_id.astype(str)\n","twitter_dogs.source = twitter_dogs.source.astype(\"category\")\n","twitter_dogs.dog_stages = twitter_dogs.dog_stages.astype(\"category\")\n","twitter_dogs['dog_breed'] = twitter_dogs['dog_breed'].astype(\"category\")"]},{"cell_type":"markdown","metadata":{"id":"by3SL5zYmrIJ"},"source":["### Test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_RDwIKivmrIJ"},"outputs":[],"source":["twitter_dogs.info()"]},{"cell_type":"markdown","metadata":{"id":"CZWaWESemrIJ"},"source":["## Storing Data\n","Save gathered, assessed, and cleaned master dataset to a CSV file named \"twitter_archive_master.csv\"."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QSkWmysjmrIJ"},"outputs":[],"source":["# Use pandas to save the twitter_dogs dataframe to a new csv file\n","\n","twitter_dogs.to_csv('twitter_archive_master.csv',encoding='utf-8', index=False)"]},{"cell_type":"markdown","metadata":{"id":"AC7yIWrMmrIJ"},"source":["## Analyzing and Visualizing Data\n","In this section, analyze and visualize your wrangled data. You must produce at least **three (3) insights and one (1) visualization.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gcBMciFbmrIJ"},"outputs":[],"source":["# convert the datatypes back to how i want them from read_csv\n","# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html\n","\n","twitter_archive_master = pd.read_csv('twitter_archive_master.csv', parse_dates=['timestamp'],\n","                                     dtype={'tweet_id': str, 'source': 'category', 'dog_stages': 'category',\n","                                            'dog_breed': 'category'})\n","twitter_archive_master.info()"]},{"cell_type":"markdown","metadata":{"id":"wjzG8C23mrIK"},"source":["### Insights:\n","1. Most popular Dog Breeds\n","\n","2. Most used Twitter source for tweeting\n","\n","3. Popular Dog Names\n","\n","4. Corelation between Retweet, Favorites and Ratings"]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"ibnZN1DMmrIK"},"source":["### Visualization"]},{"cell_type":"markdown","metadata":{"id":"LhD0VYCimrIK"},"source":["#### Most Populr Dog Breed"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xb26h-r1mrIK"},"outputs":[],"source":["# Function to reduce code repetition\n","\n","def plot_param(xlabel, ylabel, title):\n","    plt.xlabel(xlabel, fontsize=15)\n","    plt.ylabel(ylabel, fontsize=15)\n","    plt.title(title,fontsize= 20)\n","    plt.show()\n","    return None"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0qOrSOEZmrIK"},"outputs":[],"source":["twitter_archive_master.dog_breed.value_counts()[1:21].plot(kind='bar',figsize=(15,10), color='#808080')\n","plot_param('Count','Dog Breeds','Top 20 Most Rated Dog Breed')\n"]},{"cell_type":"markdown","metadata":{"id":"wHXQ3KtrmrIK"},"source":["#### Most used Twitter Source"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yhvYbqEUmrIK"},"outputs":[],"source":["twitter_archive_master.source.value_counts().plot(kind='bar',figsize=(15,10), color='#808080')\n","plt.xticks(rotation=0)\n","plot_param('Number of tweets','Source','Most Twitter Source by WeRateDogs')\n"]},{"cell_type":"markdown","metadata":{"id":"zeuEhwTxmrIK"},"source":["#### Most Popular Dog Names"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cskcSXk8mrIL"},"outputs":[],"source":["twitter_archive_master.name.value_counts()[1:21].plot(kind='bar', figsize=(15,10), color='#808080')\n","plt.xticks(rotation=0)\n","plot_param('Names','Number of Dogs','Most Common Dog Names')"]},{"cell_type":"markdown","metadata":{"id":"dmC3iDbwmrIL"},"source":["#### Corelation between Retweet, Favorites and Ratings"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5EzCYOUrmrIL"},"outputs":[],"source":["corelation = twitter_archive_master.iloc[:,[3,8,9]]"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"m6PKhQvnmrIL"},"outputs":[],"source":["corelation.corr()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G7_1-U62mrIL"},"outputs":[],"source":["# https://medium.com/@szabo.bibor/how-to-create-a-seaborn-correlation-heatmap-in-python-834c0686b88e\n","\n","plt.figure(figsize=(15,10))\n","heatmap = sns.heatmap(corelation.corr(), vmin=-1, vmax=1, annot=True, linewidths=.5)\n","heatmap.set_title('Correlation Heatmap', fontdict={'fontsize':20})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8pppVBWAmrIL"},"outputs":[],"source":["# Scatter Plot showing relationship between favorite count and retweet count\n","corelation.plot(x='favorite_count', y='retweet_count', kind='scatter', figsize=(15,10), color=('blue','red'));\n","plot_param('Favorite Count','Retweet count','Favorite and Retweet')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4mqqffqKmrIL"},"outputs":[],"source":[]}],"metadata":{"extensions":{"jupyter_dashboards":{"activeView":"report_default","version":1,"views":{"grid_default":{"cellMargin":10,"defaultCellHeight":20,"maxColumns":12,"name":"grid","type":"grid"},"report_default":{"name":"report","type":"report"}}}},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.3"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}